# F-03 · YAML Schema Loader — Task Checklist

## Checklist

**IMPORTANT**: When starting a new task, read @../../docs/task_mcp_spec_and_plan.md for context.

- [x] **S-01** (XS) Create `schema/base.py` with common Pydantic config (`validate_assignment`, `extra="forbid"`)  
  - ✅ **Completed**: Created `src/trellis_mcp/schema/base.py` with `TrellisBaseModel` class
  - ✅ **Files Created**: 
    - `src/trellis_mcp/schema/base.py` - Base Pydantic model with `validate_assignment=True` and `extra="forbid"`
    - `src/trellis_mcp/schema/__init__.py` - Package initialization with exports
  - ✅ **Configuration**: Follows project patterns with `from __future__ import annotations`, `ConfigDict`, and docstrings
- [x] **S-02** (S) Implement `ProjectModel`, `EpicModel`, `FeatureModel`, `TaskModel` (schema = 1.0 fields & enums)
  - ✅ **Completed**: Created Pydantic models for all Trellis MCP object types with schema version 1.0
  - ✅ **Files Created**: 
    - `src/trellis_mcp/schema/kind_enum.py` - KindEnum with PROJECT, EPIC, FEATURE, TASK values
    - `src/trellis_mcp/schema/status_enum.py` - StatusEnum with OPEN, IN_PROGRESS, REVIEW, DONE, DRAFT values
    - `src/trellis_mcp/schema/priority_enum.py` - PriorityEnum with HIGH, NORMAL, LOW values
    - `src/trellis_mcp/schema/base_schema.py` - BaseSchemaModel with common fields for all objects
    - `src/trellis_mcp/schema/project.py` - ProjectModel with validation for top-level objects
    - `src/trellis_mcp/schema/epic.py` - EpicModel with validation for mid-level objects
    - `src/trellis_mcp/schema/feature.py` - FeatureModel with validation for mid-level objects
    - `src/trellis_mcp/schema/task.py` - TaskModel with validation for leaf objects
  - ✅ **Features**: 
    - Schema version 1.0 with `Literal["1.0"]` field
    - Proper field validation for kind, status, parent relationships
    - Status validation per object type (projects/epics/features: draft→in-progress→done; tasks: open→in-progress→review→done)
    - Parent validation (projects: none; epics/features/tasks: required)
- [x] **S-03** (XS) Implement `load_markdown(path)` → `(frontmatter_dict, body_str)` using `ruyaml` or `frontmatter` lib  
  - ✅ **Completed**: Created `src/trellis_mcp/markdown_loader.py` with `load_markdown` function
  - ✅ **Files Created**: 
    - `src/trellis_mcp/markdown_loader.py` - Markdown loader with YAML front-matter parsing
  - ✅ **Features**: 
    - Parses YAML front-matter delimited by `---` lines
    - Returns tuple of (frontmatter_dict, body_str) as required
    - Uses `yaml.safe_load()` for security
    - Handles edge cases: missing front-matter, invalid YAML, file I/O errors
    - Proper error handling with descriptive messages
- [x] **S-04** (S) Implement `parse_object(path)` → typed model instance (select model by `kind`)
  - ✅ **Completed**: Created `src/trellis_mcp/object_parser.py` with `parse_object` function
  - ✅ **Files Created**: 
    - `src/trellis_mcp/object_parser.py` - Parser function that selects correct model based on `kind` field
    - `tests/test_object_parser.py` - Comprehensive test suite covering all object types and error cases
  - ✅ **Files Modified**:
    - `src/trellis_mcp/__init__.py` - Added export for `parse_object` function
  - ✅ **Features**: 
    - Parses markdown files with YAML front-matter into typed Pydantic model instances
    - Automatically selects appropriate model class (`ProjectModel`, `EpicModel`, `FeatureModel`, `TaskModel`) based on `kind` field
    - Comprehensive error handling for missing files, invalid YAML, missing/invalid kind field, and validation errors
    - Uses existing `load_markdown()` function for consistent file parsing
    - Full type safety with Union type alias `TrellisObjectModel` 
- [x] **S-05** (S) Validation: required fields per kind, enum membership, parent existence (via `path_resolver`)
  - ✅ **Completed**: Created comprehensive validation utilities module with parent existence validation
  - ✅ **Files Created**: 
    - `src/trellis_mcp/validation.py` - Comprehensive validation utilities with parent existence checking
    - `tests/test_validation.py` - Complete test suite covering all validation scenarios
  - ✅ **Files Modified**:
    - `src/trellis_mcp/__init__.py` - Added validation functions to package exports
  - ✅ **Features**: 
    - Required fields validation per object kind (projects, epics, features, tasks)
    - Enum membership validation for kind, status, and priority fields
    - Parent existence validation using path_resolver (checks filesystem for parent objects)
    - Status validation per object kind (proper lifecycle states)
    - Comprehensive object data validation function combining all validations
    - Pydantic field validator factory for integration with existing models
- [x] **S-06** (M) Validation: **acyclic prerequisites** — DFS over prerequisites graph, raise `CircularDependencyError`
  - ✅ **Completed**: Created comprehensive cycle detection validation system with DFS algorithm
  - ✅ **Files Created**:
    - `src/trellis_mcp/validation.py` - Added `CircularDependencyError` exception class
    - `src/trellis_mcp/validation.py` - Added `get_all_objects()` function to load all objects from filesystem
    - `src/trellis_mcp/validation.py` - Added `build_prerequisites_graph()` function to create adjacency list
    - `src/trellis_mcp/validation.py` - Added `detect_cycle_dfs()` function implementing DFS cycle detection
    - `src/trellis_mcp/validation.py` - Added `validate_acyclic_prerequisites()` main validation function
    - `tests/test_validation.py` - Added comprehensive test suite with 25 new tests covering all functionality
  - ✅ **Files Modified**:
    - `src/trellis_mcp/__init__.py` - Added exports for new validation functions and exception
  - ✅ **Features**: 
    - Detects circular dependencies in prerequisites using depth-first search algorithm
    - Handles self-referencing cycles (A -> A)
    - Detects simple cycles (A -> B -> A) 
    - Detects complex multi-node cycles (A -> B -> C -> D -> B)
    - Raises `CircularDependencyError` with detailed cycle path information
    - Supports objects with and without ID prefixes (T-, F-, E-, P-)
    - Comprehensive error handling for invalid directories and parsing errors
- [x] **S-07** (XS) Implement `dump_object(model)` → markdown string with updated `updated` timestamp  
  - ✅ **Completed**: Created `src/trellis_mcp/object_dumper.py` with `dump_object` function that converts Pydantic models to markdown with YAML front-matter
  - ✅ **Files Created**: 
    - `src/trellis_mcp/object_dumper.py` - Main function that serializes Trellis objects to markdown format
  - ✅ **Files Modified**:
    - `src/trellis_mcp/__init__.py` - Added export for `dump_object` function
  - ✅ **Features**: 
    - Converts any `TrellisObjectModel` (Project, Epic, Feature, Task) to markdown with YAML front-matter
    - Automatically updates the `updated` timestamp to current time during serialization
    - Handles proper serialization of datetime objects (ISO format), enums (string values), and None values
    - Uses `yaml.safe_dump()` for security with consistent formatting (`default_flow_style=False`, `sort_keys=False`)
    - Returns markdown string with `---` delimited YAML front-matter followed by empty body
    - Includes comprehensive helper function `_serialize_model_dict()` for proper type conversion
- [x] **S-08** (XS) Helper `write_object(model)` that atomically writes file with `tempfile` + `replace`  
  - ✅ **Completed**: Created `write_object` function in `src/trellis_mcp/object_dumper.py` that atomically writes Trellis objects to filesystem
  - ✅ **Files Modified**: 
    - `src/trellis_mcp/object_dumper.py` - Added `write_object` function with atomic file operations using `tempfile` and `os.replace`
    - `src/trellis_mcp/__init__.py` - Added export for `write_object` function
  - ✅ **Features**: 
    - Atomically writes Trellis object models to filesystem using temporary files and atomic replace operations
    - Uses `id_to_path` to determine target file location based on object kind and ID
    - Creates parent directories automatically using `ensure_parent_dirs`
    - Uses `tempfile.NamedTemporaryFile` in same directory for atomic operations
    - Implements proper error handling with cleanup of temporary files on failure
    - Ensures data is flushed to disk with `os.fsync()` before atomic replacement
    - Handles all object types (Project, Epic, Feature, Task) consistently  
- [x] **S-09** (XS) Unit tests: happy-path load & dump round-trip for each kind  
  - ✅ **Completed**: Created comprehensive round-trip test suite for all object kinds
  - ✅ **Files Created**: 
    - `tests/test_object_roundtrip.py` - Complete test suite with 15 test cases covering all object kinds and edge cases
  - ✅ **Features**: 
    - Round-trip tests for all 4 object kinds (PROJECT, EPIC, FEATURE, TASK) with minimal and full field sets
    - Tests for data integrity preservation through multiple round-trips
    - Edge case testing: empty prerequisites, null worktree fields, all status/priority enum values
    - Complex prerequisites testing with mixed prefixed/non-prefixed IDs
    - DateTime precision preservation testing 
    - All tests pass with 100% coverage of dump_object() and parse_object() happy paths  
- [x] **S-10** (S) Unit tests: failure cases (missing field, bad enum, bad parent, circular prereqs)
  - ✅ **Completed**: Created comprehensive test suite for validation failure cases
  - ✅ **Files Created**: 
    - `tests/test_validation_failures.py` - Complete test suite with 43 test cases covering all failure scenarios
  - ✅ **Features**: 
    - Missing field failures: Tests for missing required fields for all object types (project, epic, feature, task)
    - Bad enum failures: Tests for invalid kind, status, and priority enum values
    - Bad parent failures: Tests for invalid parent relationships (project with parent, missing parents, non-existent parents)
    - Circular prerequisites failures: Tests for self-referencing, simple, and complex circular dependencies
    - Pydantic model failures: Tests for model-level validation errors
    - Parse object failures: Tests for object parsing error scenarios
  - ✅ **Quality**: All tests pass, proper type annotations, follows project conventions  
- [x] **S-11** (M) Integration test: load **sample repo tree** (~6 objects) and assert all models valid, graph acyclic
  - ✅ **Completed**: Created comprehensive integration test that loads a sample repository tree with 6 objects and validates all models and acyclic prerequisites
  - ✅ **Files Created**: 
    - `tests/test_integration_schema_loading.py` - Integration test with sample repo tree validation
  - ✅ **Files Modified**:
    - `tests/test_object_roundtrip.py` - Removed unused pytest import
    - `tests/test_validation_failures.py` - Removed unused EpicModel and FeatureModel imports
  - ✅ **Features**: 
    - Creates sample repository structure with 6 objects: 1 project, 1 epic, 1 feature, 3 tasks
    - Validates all objects load correctly using `get_all_objects()` function
    - Validates all models pass Pydantic validation using `validate_object_data()`
    - Validates parent-child relationships are correct across the hierarchy
    - Validates prerequisites graph is acyclic using `validate_acyclic_prerequisites()`
    - Tests different object statuses (draft, in-progress, done) and priorities
    - Tests prerequisite chains (setup-database → add-password-reset → implement-jwt)
    - Follows existing test patterns with temp_dir fixture and proper cleanup

### Quality Gates
* All models include `schema_version = Literal[1.0]` field and reject mismatches.
* Circular prereq detection catches simple and multi-node cycles.
* Unit + integration tests run under pre-commit and CI; coverage ≥ 90 % for `schema/` package.
* No file is left partially written (atomic `replace` used).
