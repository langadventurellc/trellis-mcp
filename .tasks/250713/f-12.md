# F-12 · System Logging & Prune — Task Checklist

## Checklist

**IMPORTANT**: When starting a new task, read @../../docs/task_mcp_spec_and_plan.md for context.

- [x] **S-01** (XS) Define `LOG_DIR`, daily filename pattern, RFC 3339 timestamp helper
  - Added `log_dir: Path` field to Settings class with default `./logs`
  - Created `daily_log_filename()` function for YYYY-MM-DD.log format
  - Created `rfc3339_timestamp()` function for RFC 3339 compliant timestamps
  - Files created: `log_filename.py`, `rfc3339_timestamp.py`
  - Files modified: `settings.py`  
- [x] **S-02** (S) Implement `logger.py` → `write_event(level, msg, **fields)` (thread-safe append)
  - Created `logger.py` with thread-safe `write_event()` function
  - Function accepts level, msg, and additional fields as keyword arguments
  - Uses global threading lock for thread-safe file operations
  - Outputs JSONL format with schema: {ts, level, msg, ...fields}
  - Integrates with existing `daily_log_filename()` and `rfc3339_timestamp()` utilities
  - Uses settings.log_dir for log file location
  - Automatically creates log directory if it doesn't exist
  - Proper error handling for JSON serialization and file operations
  - Files created: `logger.py`  
- [x] **S-03** (S) Middleware: wrap every JSON-RPC call; log `method`, `duration ms`, `status`
  - Created `JsonRpcLoggingMiddleware` class that intercepts all JSON-RPC tool calls
  - Logs method name, duration in milliseconds, and status (success/error) using existing `write_event()`
  - Registered middleware in `create_server()` function to wrap all JSON-RPC calls
  - Implemented thread-safe logging with timing using `time.perf_counter()`
  - Added comprehensive tests covering successful/failed calls, duration measurement, and concurrent safety
  - All 716 tests pass including 6 new middleware-specific tests
  - Files created: `json_rpc_logging_middleware.py`, `test_json_rpc_logging_middleware.py`
  - Files modified: `server.py`  
- [x] **S-04** (XS) Config setting `log_retention_days` (default 30) in Settings class  
  - Added `log_retention_days: int` field to Settings class with default value of 30
  - Configured with `gt=0` validation to ensure positive integer values only
  - Added descriptive documentation for automatic log cleanup configuration
  - Follows existing patterns for pydantic Field configuration with validation
  - Configurable via `MCP_LOG_RETENTION_DAYS` environment variable
  - Files modified: `settings.py`
- [x] **S-05** (S) Implement `prune_logs()` utility — delete files older than retention window  
  - Created thread-safe `prune_logs()` function in `prune_logs.py`
  - Scans log directory for daily log files matching YYYY-MM-DD.log pattern
  - Removes files older than configured retention window (settings.log_retention_days)
  - Returns count of removed files for caller feedback
  - Thread-safe using global lock to prevent concurrent pruning operations
  - Comprehensive error handling for filesystem operations
  - Validates retention_days setting (must be > 0)
  - Gracefully handles missing log directory (returns 0)
  - Uses regex pattern matching for robust filename validation
  - Files created: `prune_logs.py`
  - All quality checks pass: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (716 passing)  
- [x] **S-06** (XS) Call `prune_logs()` at server startup if retention > 0
  - Added prune_logs() call in create_server() function after middleware registration
  - Only calls prune_logs() if settings.log_retention_days > 0 per task requirements
  - Passes settings parameter to prune_logs() for consistency
  - Includes error handling to prevent server startup failures if log pruning fails
  - Import added for prune_logs function from .prune_logs module
  - Files modified: `server.py`  
- [x] **S-07** (S) Add CLI sub-command `trellis-mcp prune-logs` (runs utility manually)
  - Added `prune-logs` command to CLI following established patterns in `cli.py`
  - Implemented `--dry-run` flag to show files that would be removed without deleting
  - Implemented `--retention-days` option to override configured retention period
  - Uses existing `prune_logs()` function from `prune_logs.py` module
  - Follows consistent error handling patterns with `click.ClickException`
  - Provides user feedback with file counts and debug information
  - Exits with status 0 and prints "X files removed" as required by quality gates
  - Comprehensive help text with usage examples
  - Files modified: `cli.py`
  - All quality checks pass: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (716 passing)  
- [x] **S-08** (XS) Unit tests: logger writes JSONL, fields present, concurrent writes safe  
  - Created comprehensive unit tests in `tests/unit/test_logger.py` covering all task requirements
  - **JSONL Format Tests**: Verified write_event() produces valid JSON lines parseable with json.loads()
  - **Field Presence Tests**: Ensured required fields (ts, level, msg) and additional fields are included
  - **Concurrent Safety Tests**: Tested multiple threads writing simultaneously without race conditions
  - Test coverage includes: single/multiple entries, various data types, RFC 3339 timestamp validation
  - Concurrent testing with ThreadPoolExecutor validates thread-safe file operations
  - All 9 new unit tests pass with comprehensive edge case coverage
  - Files created: `tests/unit/test_logger.py`
  - Quality checks: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (725 passing)
- [x] **S-09** (XS) Unit tests: prune keeps recent files, removes old ones (+ time-freeze)
  - Created comprehensive unit tests in `tests/unit/test_prune_logs.py` covering all retention scenarios
  - **Recent files kept**: Tests verify files within retention window are preserved
  - **Old files removed**: Tests verify files older than retention window are deleted
  - **Time-freeze testing**: Uses freezegun library to freeze time at 2024-01-15 for predictable test outcomes
  - **Boundary testing**: Tests exact cutoff scenarios (files at retention boundary)
  - **Edge cases**: Empty directory, non-existent directory, invalid file patterns, different retention periods
  - **Thread safety**: Tests concurrent access behavior
  - **Return value validation**: Verifies correct count of removed files is returned
  - All 11 new unit tests pass with comprehensive coverage of prune_logs() function behavior
  - Added freezegun>=1.5.3 as development dependency for time mocking in tests
  - Files created: `tests/unit/test_prune_logs.py`
  - Quality checks: ✅ Tests (736 passing) ✅ Type Check ✅ Format  
- [x] **S-10** (M) Integration test: start server, invoke two RPCs, verify log file content, run prune, assert old dummy file removed
  - Created comprehensive integration test in `tests/integration/test_logging_integration.py`
  - **Fixed logger settings issue**: Modified `logger.py` to accept optional `Settings` parameter instead of always creating new instance
  - **Enhanced middleware**: Updated `JsonRpcLoggingMiddleware` to accept settings and extract actual tool names from MCP calls
  - **Updated server**: Modified server to pass settings to middleware for consistent configuration
  - **Test validates**: Server startup, RPC logging with proper JSONL format, log file pruning, and file retention logic
  - **Quality checks**: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (737 passing)
  - Files created: `tests/integration/test_logging_integration.py`
  - Files modified: `logger.py`, `json_rpc_logging_middleware.py`, `server.py`

## Post-Implementation Code Review Tasks

**Code Review Date**: 2025-07-15  
**Reviewer**: Gemini AI  
**Status**: New tasks identified for improvement

- [x] **S-11** (S) Fix DRY violation in CLI prune-logs command
  - **Issue**: The `prune-logs` CLI command duplicates log scanning logic from `prune_logs.py` for its `--dry-run` functionality
  - **Solution**: Modify `prune_logs()` function to accept a `dry_run: bool` parameter. When `True`, it should return a list of files that would be deleted instead of performing actual deletion
  - **Benefits**: Centralizes core logic, eliminates code duplication, ensures consistency between dry-run and actual execution
  - **Implementation**: Modified `prune_logs()` function to accept `dry_run: bool = False` parameter. When `True`, returns `list[Path]` of files that would be deleted; when `False`, deletes files and returns `int` count. Updated CLI command to use centralized function, removing ~40 lines of duplicated scanning logic. Added comprehensive dry-run tests covering edge cases, consistency, and different retention periods.
  - **Files modified**: `src/trellis_mcp/prune_logs.py`, `src/trellis_mcp/cli.py`
  - **Tests added**: `tests/unit/test_prune_logs.py` (added TestPruneLogsDryRun class with 8 comprehensive test cases)
  - **Quality checks**: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (745 passing)

- [x] **S-12** (XS) Add logging for server startup log pruning failures
  - **Issue**: Server startup log pruning fails silently with `except Exception: pass` in `server.py`
  - **Solution**: Replace silent exception handling with proper logging using `write_event()` function
  - **Implementation**: Log the exception details at ERROR level so failures are recorded but don't prevent server startup
  - **Files to modify**: `src/trellis_mcp/server.py`
  - **Example**: `write_event("ERROR", "Log pruning failed during startup", error=str(e))`
  - **Completed**: Added `write_event` import and replaced silent exception handling with proper logging. Server startup log pruning failures are now logged at ERROR level with exception details while maintaining non-blocking behavior for server startup.
  - **Files modified**: `src/trellis_mcp/server.py`
  - **Quality checks**: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (745 passing)

- [x] **S-13** (S) Replace local time usage with UTC for consistency
  - **Issue**: System uses `datetime.now()` and `datetime.utcnow()` which can cause timezone-related issues
  - **Solution**: Use `datetime.now(timezone.utc)` consistently throughout the system
  - **Rationale**: UTC prevents issues with timezone changes, DST shifts, and ensures consistent behavior across deployments
  - **Implementation**: Replaced all `datetime.now()` and `datetime.utcnow()` calls with `datetime.now(timezone.utc)` in logging system files. Added `timezone` import to all affected files. Fixed RFC 3339 timestamp function to properly handle UTC timezone-aware datetimes and maintain "Z" suffix format. Updated date parsing in prune_logs to use UTC timezone for consistent comparisons.
  - **Files modified**: `src/trellis_mcp/log_filename.py`, `src/trellis_mcp/rfc3339_timestamp.py`, `src/trellis_mcp/prune_logs.py`
  - **Quality checks**: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (745 passing)

- [x] **S-14** (XS) Fix documentation error in rfc3339_timestamp() docstring
  - **Issue**: Docstring example shows incorrect output format for `datetime(2025, 7, 15, 19, 12, 0)`
  - **Current**: Shows `'2025-07-15T19:12:00'` but code produces `'2025-07-15T19:12:00Z'`
  - **Solution**: Update docstring example to match actual code behavior
  - **Implementation**: Fixed docstring example on line 25 to show `'2025-07-15T19:12:00Z'` with Z suffix to match actual code behavior when naive datetime is passed
  - **Files modified**: `src/trellis_mcp/rfc3339_timestamp.py`
  - **Quality checks**: ✅ Format ✅ Lint ✅ Type Check ✅ Tests (745 passing)

### Quality Gates
* Log entry schema: `{ts, level, msg, details…}`; must parse with `json.loads`.
* Concurrency simulated with `ThreadPoolExecutor` passes without race/errors.
* Default retention (30 days) honoured; setting `0` disables pruning.
* CLI `prune-logs` exits 0 and prints "X files removed".
* Pre-commit & CI hooks green.
